# -*- coding: utf-8 -*-
"""Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GSIkhCpE6qX2iX1-4k4xOdEYT-1ZmSbo
"""

import numpy as np
import cv2
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from skimage.measure import shannon_entropy
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
import os

# ðŸ“Œ Step 1: Define the LAB Autoencoder Model
class LABAutoencoder(nn.Module):
    def __init__(self):
        super(LABAutoencoder, self).__init__()

        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),
            nn.ReLU()
        )

        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

# Load trained autoencoder model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
autoencoder = LABAutoencoder().to(device)
autoencoder.load_state_dict(torch.load("lab_autoencoder.pth", map_location=device))
autoencoder.eval()

# ðŸ“Œ Step 2: Convert Enhanced Image to LAB Channels
def convert_to_LAB(image_path):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    L, A, B = cv2.split(image)

    # Convert to tensor for autoencoder processing
    lab_image = np.stack([L, A, B], axis=0).astype(np.float32) / 255.0
    lab_tensor = torch.tensor(lab_image).unsqueeze(0).to(device)  # Shape: (1, 3, H, W)

    # Pass through autoencoder
    with torch.no_grad():
        reconstructed_tensor = autoencoder(lab_tensor)

    # Convert back to numpy
    reconstructed_image = (reconstructed_tensor.squeeze(0).cpu().numpy() * 255).astype(np.uint8)
    return reconstructed_image[0], reconstructed_image[1], reconstructed_image[2]  # L, A, B

# ðŸ“Œ Step 3: Compute Dynamic Number of Shares
def compute_dynamic_n_shares(image):
    entropy = shannon_entropy(image)
    return min(5, max(3, int(entropy // 2)))  # Ensures 3-5 shares

# ðŸ“Œ Step 4: AES-256 Key Generation & Encryption
def generate_aes_key():
    return os.urandom(32)

def encrypt_channel(channel, key):
    cipher = AES.new(key, AES.MODE_CBC)
    flat_data = channel.flatten()
    padded_data = pad(flat_data.tobytes(), AES.block_size)
    ciphertext = cipher.encrypt(padded_data)
    return ciphertext, cipher.iv, len(padded_data) - len(flat_data)

# ðŸ“Œ Step 5: Generate Shares
def generate_dynamic_shares(encrypted_data, img_shape):
    h, w = img_shape
    encrypted_array = np.frombuffer(encrypted_data, dtype=np.uint8)[:h*w].reshape(h, w)
    n_shares = compute_dynamic_n_shares(encrypted_array)

    shares = [np.random.randint(0, 256, (h, w), dtype=np.uint8) for _ in range(n_shares - 1)]

    # ðŸŽ¯ Convert to int16 before subtraction to avoid overflow
    final_share = (encrypted_array.astype(np.int16) - np.sum(shares, axis=0, dtype=np.int16)) % 256

    shares.append(final_share.astype(np.uint8))

    return shares

# ðŸ“Œ Step 6: Reconstruct Encrypted Image
def reconstruct_encrypted_image(shares):
    # Convert to a data type that can handle larger values before the modulo
    reconstructed = np.sum(shares, axis=0, dtype=np.int16) % 256
    # Convert back to uint8 for consistency with the expected data type
    return reconstructed.astype(np.uint8)
# ðŸ“Œ Step 7: Decryption
def decrypt_channel(encrypted_data, key, iv, original_shape):
    cipher = AES.new(key, AES.MODE_CBC, iv)
    decrypted_padded = cipher.decrypt(encrypted_data)
    decrypted_flat = unpad(decrypted_padded, AES.block_size)
    return np.frombuffer(decrypted_flat, dtype=np.uint8).reshape(original_shape)

# ðŸ“Œ Step 8: Display Shares
def display_shares(shares, title):
    plt.figure(figsize=(10, 5))
    for i, share in enumerate(shares):
        plt.subplot(1, len(shares), i + 1)
        plt.imshow(share)
        plt.title(f"{title} Share {i+1}")
        plt.axis("off")
    plt.show()

# ðŸ“Œ Step 9: Main Execution
image_path = "/content/peppers.jpg"

# Convert & Pass through Autoencoder
L, A, B = convert_to_LAB(image_path)

# Generate AES Keys
L_key, A_key, B_key = generate_aes_key(), generate_aes_key(), generate_aes_key()

# Encrypt LAB channels
L_encrypted, L_iv, L_padding = encrypt_channel(L, L_key)
A_encrypted, A_iv, A_padding = encrypt_channel(A, A_key)
B_encrypted, B_iv, B_padding = encrypt_channel(B, B_key)

# Generate Shares
L_shares = generate_dynamic_shares(L_encrypted, L.shape)
A_shares = generate_dynamic_shares(A_encrypted, A.shape)
B_shares = generate_dynamic_shares(B_encrypted, B.shape)

# ðŸ“Œ Display Shares for Each LAB Channel
display_shares(L_shares, "L")
display_shares(A_shares, "A")
display_shares(B_shares, "B")

# Reconstruct Encrypted LAB Channels
L_encrypted_reconstructed = reconstruct_encrypted_image(L_shares)
A_encrypted_reconstructed = reconstruct_encrypted_image(A_shares)
B_encrypted_reconstructed = reconstruct_encrypted_image(B_shares)

# Decrypt LAB Channels
L_decrypted = decrypt_channel(L_encrypted, L_key, L_iv, L.shape)
A_decrypted = decrypt_channel(A_encrypted, A_key, A_iv, A.shape)
B_decrypted = decrypt_channel(B_encrypted, B_key, B_iv, B.shape)

# Display Results
def display_results(original, reconstructed, title):
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(original)
    plt.title(f"Original {title} Channel")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(reconstructed)
    plt.title(f"Reconstructed {title} Channel")
    plt.axis("off")

    plt.show()

display_results(L, L_decrypted, "L")
display_results(A, A_decrypted, "A")
display_results(B, B_decrypted, "B")

# Merge & Convert Back to BGR
reconstructed_lab = cv2.merge([L_decrypted, A_decrypted, B_decrypted])
final_reconstructed = cv2.cvtColor(reconstructed_lab, cv2.COLOR_LAB2BGR)

# Display Final Image
plt.figure(figsize=(5, 5))
plt.imshow(cv2.cvtColor(final_reconstructed, cv2.COLOR_BGR2RGB))
plt.title("Final Reconstructed Image with Autoencoder & AES")
plt.axis("off")
plt.show()

"""# ENTROPY JUSTIFICATION FOR 1.5 AS DIVISOR PROVED EMPIRICALLY"""

import numpy as np
import cv2
from skimage.measure import shannon_entropy
import matplotlib.pyplot as plt
from google.colab import files
import io



def calculate_channel_entropies(image_path):
    if not os.path.exists(image_path):
        print(f"Error: File not found at path: {image_path}")
        return None

    image = cv2.imread(image_path)

    if image is None:
        print(f"Error: Could not read image at {image_path}. Check file format.")
        return None

    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)

    # Split the channels (L, A, B are 0, 1, 2 respectively)
    L, A, B = cv2.split(lab_image)

    h_l = shannon_entropy(L)
    h_a = shannon_entropy(A)
    h_b = shannon_entropy(B)

    print(f"\n--- Entropy (H) Results for {os.path.basename(image_path)} ---")
    print(f"Luminance Channel (H_L): {h_l:.4f}")
    print(f"Chrominance A (H_A):   {h_a:.4f}")
    print(f"Chrominance B (H_B):   {h_b:.4f}")

    return {'L': h_l, 'A': h_a, 'B': h_b}

def determine_shares(entropy_value, divisor):
    """
    Applies the dynamic share allocation formula:
    n_x = min(5, max(3, floor(H_x / divisor)))
    """
    if divisor == 0:
        return 5

    n_shares = np.floor(entropy_value / divisor)

    return int(min(5, max(3, n_shares)))

# --- 2. ANALYSIS AND VISUALIZATION FUNCTIONS ---

def generate_justification_table(entropies):

    divisors = [1.0, 1.5, 2.0]

    print("\n--- Share Allocation Comparison for Entropy Justification ---")
    print("{:<10} | {:<10} | {:<8} | {:<8} | {:<8}".format("Channel", "Entropy (H)", "Div 1.0", "Div 1.5", "Div 2.0"))
    print("-" * 50)

    all_results = []

    for channel, H in entropies.items():
        n10 = determine_shares(H, 1.0)
        n15 = determine_shares(H, 1.5)
        n20 = determine_shares(H, 2.0)

        all_results.append({
            'Channel': channel,
            'H': H,
            '1.0': n10,
            '1.5': n15,
            '2.0': n20
        })

        print("{:<10} | {:<10.4f} | {:<8} | {:<8} | {:<8}".format(channel, H, n10, n15, n20))

    return all_results

def plot_entropy_division(entropies):


    divisor_labels = ['1.0', '1.5 (Proposed)', '2.0']

    # Map results to plot structure
    H_values = list(entropies.values())
    channels = list(entropies.keys())

    n_shares_10 = [determine_shares(H, 1.0) for H in H_values]
    n_shares_15 = [determine_shares(H, 1.5) for H in H_values]
    n_shares_20 = [determine_shares(H, 2.0) for H in H_values]

    x = np.arange(len(channels))
    width = 0.25
    fig, ax = plt.subplots(figsize=(8, 5))

    rects1 = ax.bar(x - width, n_shares_10, width, label='Divisor 1.0', color='skyblue')
    rects2 = ax.bar(x, n_shares_15, width, label='Divisor 1.5 (Proposed)', color='teal')
    rects3 = ax.bar(x + width, n_shares_20, width, label='Divisor 2.0', color='salmon')

    # Add some text for labels, titles and custom x-axis tick labels, etc.
    ax.set_ylabel('Number of Shares (n_x)')
    ax.set_xlabel('LAB Channel (H values listed below)')
    ax.set_title('Impact of Entropy Divisor on Dynamic Share Allocation')
    ax.set_xticks(x)
    ax.set_ylim(2.5, 5.5)
    ax.legend(loc='upper right')

    # Add H values below the channel names
    ax.set_xticklabels([f'{ch}\nH={H:.2f}' for ch, H in entropies.items()])

    # Label the bars with the share count
    def autolabel(rects):
        for rect in rects:
            height = rect.get_height()
            ax.annotate(f'{height}',
                        xy=(rect.get_x() + rect.get_width() / 2, height),
                        xytext=(0, 3),  # 3 points vertical offset
                        textcoords="offset points",
                        ha='center', va='bottom')

    autolabel(rects1)
    autolabel(rects2)
    autolabel(rects3)

    fig.tight_layout()
    plt.show()

# --- 3. MAIN EXECUTION BLOCK ---

def run_entropy_analysis():


    # 1. Upload the image file
    print("Please upload one standard test image (e.g., 'Baboon.jpg', 'Peppers.jpg'):")
    uploaded = files.upload()

    if not uploaded:
        print("No file uploaded. Analysis cancelled.")
        return

    # Get the file name (assuming only one was uploaded)
    image_name = list(uploaded.keys())[0]

    # 2. Calculate entropies
    entropies = calculate_channel_entropies(image_name)

    if entropies is None:
        return

    # 3. Generate table and plot
    generate_justification_table(entropies)
    plot_entropy_division(entropies)



# Run the main function
run_entropy_analysis()

"""# CODE FOR QUALITATIVE COMPARISSION OF ZOOMED IN SECTION OF ORIGINAL AND RECONSTRUCTED IMAGE FOR EACH L,A AND B CHANNEL"""

import numpy as np
import cv2
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from skimage.measure import shannon_entropy
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
import os
import io

class LABAutoencoder(nn.Module):
    def __init__(self):
        super(LABAutoencoder, self).__init__()
        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),
            nn.ReLU()
        )
        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()
        )
    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
autoencoder = LABAutoencoder().to(device)

try:
    autoencoder.load_state_dict(torch.load("lab_autoencoder.pth", map_location=device))
    autoencoder.eval()
except FileNotFoundError:
    print("WARNING: 'lab_autoencoder.pth' not found. Model weights are required for enhancement.")

def convert_to_LAB(image_path):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    L, A, B = cv2.split(image)

    lab_image = np.stack([L, A, B], axis=0).astype(np.float32) / 255.0
    lab_tensor = torch.tensor(lab_image).unsqueeze(0).to(device)

    with torch.no_grad():
        reconstructed_tensor = autoencoder(lab_tensor)

    reconstructed_image = (reconstructed_tensor.squeeze(0).cpu().numpy() * 255).astype(np.uint8)
    return reconstructed_image[0], reconstructed_image[1], reconstructed_image[2]

def compute_dynamic_n_shares(image):
    entropy = shannon_entropy(image)
    return min(5, max(3, int(entropy // 1.5)))

def generate_aes_key():
    return os.urandom(32)

def encrypt_channel(channel, key):
    cipher = AES.new(key, AES.MODE_CBC)
    flat_data = channel.flatten()
    padded_data = pad(flat_data.tobytes(), AES.block_size)
    ciphertext = cipher.encrypt(padded_data)
    return ciphertext, cipher.iv, len(padded_data) - len(flat_data)

def generate_dynamic_shares(encrypted_data, img_shape):
    h, w = img_shape
    encrypted_array = np.frombuffer(encrypted_data, dtype=np.uint8)[:h*w].reshape(h, w)
    n_shares = compute_dynamic_n_shares(encrypted_array)

    shares = [np.random.randint(0, 256, (h, w), dtype=np.uint8) for _ in range(n_shares - 1)]

    shares_sum = np.sum(shares, axis=0, dtype=np.int16)
    final_share = (encrypted_array.astype(np.int16) - shares_sum) % 256

    shares.append(final_share.astype(np.uint8))
    return shares

def reconstruct_encrypted_image(shares):
    reconstructed = np.sum(shares, axis=0, dtype=np.int16) % 256
    return reconstructed.astype(np.uint8)

def decrypt_channel(encrypted_data, key, iv, original_shape):
    decrypted_padded = cipher.decrypt(encrypted_data)

    decrypted_flat = unpad(decrypted_padded, AES.block_size)

    return np.frombuffer(decrypted_flat, dtype=np.uint8).reshape(original_shape)



# Recommended ROI for the Peppers image (approx. 512x512)
H_START = 50
H_END   = 178
W_START = 100
W_END   = 228

def perform_qualitative_comparison(original_channel, reconstructed_channel, channel_name, ss_metric):

    original_crop = original_channel[H_START:H_END, W_START:W_END]

    reconstructed_crop = reconstructed_channel[H_START:H_END, W_START:W_END]

    fig, axes = plt.subplots(1, 2, figsize=(8, 4), dpi=300) # Use 300 DPI for high-res output

    axes[0].imshow(original_crop, cmap='viridis')
    axes[0].set_title(f"Original {channel_name} Channel (Zoom)", fontsize=10)
    axes[0].axis('off')

    axes[1].imshow(reconstructed_crop, cmap='viridis')
    axes[1].set_title(f"Reconstructed {channel_name} Channel (Zoom)", fontsize=10)
    axes[1].axis('off')

    plt.suptitle(
        f"Qualitative Comparison (Peppers - SSIM: {ss_metric:.4f}): Structural Preservation in the {channel_name} Channel",
        fontsize=12
    )
    plt.tight_layout()
    plt.show()


image_path = "/content/peppers.jpg"
PEPPERS_SSIM = 0.9385 # Value from your Table II

L_orig, A_orig, B_orig = convert_to_LAB(image_path)

L_key, A_key, B_key = generate_aes_key(), generate_aes_key(), generate_aes_key()

L_encrypted, L_iv, L_padding = encrypt_channel(L_orig, L_key)
A_encrypted, A_iv, A_padding = encrypt_channel(A_orig, A_key)
B_encrypted, B_iv, B_padding = encrypt_channel(B_orig, B_key)


L_shares = generate_dynamic_shares(L_encrypted, L_orig.shape)
A_shares = generate_dynamic_shares(A_encrypted, A_orig.shape)
B_shares = generate_dynamic_shares(B_encrypted, B_orig.shape)


L_decrypted = decrypt_channel(L_encrypted, L_key, L_iv, L_orig.shape)
A_decrypted = decrypt_channel(A_encrypted, A_key, A_iv, A_orig.shape)
B_decrypted = decrypt_channel(B_encrypted, B_key, B_iv, B_orig.shape)



perform_qualitative_comparison(L_orig, L_decrypted, "Luminance (L)", PEPPERS_SSIM)


perform_qualitative_comparison(A_orig, A_decrypted, "Chrominance (A)", PEPPERS_SSIM)

perform_qualitative_comparison(B_orig, B_decrypted, "Chrominance (B)", PEPPERS_SSIM)

"""# CODE FOR QUALITATIVE COMPARISSION OF ZOOMED IN SECTION OF ORIGINAL AND RECONSTRUCTED IMAGE FOR FULL COLOR IMAGE"""

import numpy as np
import cv2
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from skimage.measure import shannon_entropy
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
import os
import io

class LABAutoencoder(nn.Module):
    def __init__(self):
        super(LABAutoencoder, self).__init__()
        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),
            nn.ReLU()
        )
        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()
        )
    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
autoencoder = LABAutoencoder().to(device)

try:
    autoencoder.load_state_dict(torch.load("lab_autoencoder.pth", map_location=device))
    autoencoder.eval()
except FileNotFoundError:
    print("WARNING: 'lab_autoencoder.pth' not found. Model weights are required for enhancement.")

def convert_to_LAB(image_path):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    L, A, B = cv2.split(image)
    lab_image = np.stack([L, A, B], axis=0).astype(np.float32) / 255.0
    lab_tensor = torch.tensor(lab_image).unsqueeze(0).to(device)

    with torch.no_grad():
        reconstructed_tensor = autoencoder(lab_tensor)

    reconstructed_image = (reconstructed_tensor.squeeze(0).cpu().numpy() * 255).astype(np.uint8)
    return reconstructed_image[0], reconstructed_image[1], reconstructed_image[2]

def compute_dynamic_n_shares(image):
    entropy = shannon_entropy(image)
    return min(5, max(3, int(entropy // 1.5)))

def generate_aes_key():
    return os.urandom(32)

def encrypt_channel(channel, key):
    cipher = AES.new(key, AES.MODE_CBC)
    flat_data = channel.flatten()
    padded_data = pad(flat_data.tobytes(), AES.block_size)
    ciphertext = cipher.encrypt(padded_data)
    return ciphertext, cipher.iv, len(padded_data) - len(flat_data)

def generate_dynamic_shares(encrypted_data, img_shape):
    h, w = img_shape
    encrypted_array = np.frombuffer(encrypted_data, dtype=np.uint8)[:h*w].reshape(h, w)
    n_shares = compute_dynamic_n_shares(encrypted_array)

    shares = [np.random.randint(0, 256, (h, w), dtype=np.uint8) for _ in range(n_shares - 1)]

    shares_sum = np.sum(shares, axis=0, dtype=np.int16)
    final_share = (encrypted_array.astype(np.int16) - shares_sum) % 256

    shares.append(final_share.astype(np.uint8))
    return shares

def decrypt_channel(encrypted_data, key, iv, original_shape):
    cipher = AES.new(key, AES.MODE_CBC, iv)
    decrypted_padded = cipher.decrypt(encrypted_data)
    decrypted_flat = unpad(decrypted_padded, AES.block_size)
    return np.frombuffer(decrypted_flat, dtype=np.uint8).reshape(original_shape)


# 128x128 ROI for high-detail area in Peppers image
H_START = 50
H_END   = 178
W_START = 100
W_END   = 228

def perform_qualitative_comparison_color(L_orig, A_orig, B_orig, L_decrypted, A_decrypted, B_decrypted, ss_metric):

    original_lab = cv2.merge([L_orig, A_orig, B_orig])
    reconstructed_lab = cv2.merge([L_decrypted, A_decrypted, B_decrypted])

    original_rgb = cv2.cvtColor(original_lab, cv2.COLOR_LAB2RGB)
    reconstructed_rgb = cv2.cvtColor(reconstructed_lab, cv2.COLOR_LAB2RGB)

    original_crop = original_rgb[H_START:H_END, W_START:W_END]

    reconstructed_crop = reconstructed_rgb[H_START:H_END, W_START:W_END]

    fig, axes = plt.subplots(1, 2, figsize=(8, 4), dpi=300) # Use 300 DPI for high-res output

    # Display Original Crop
    axes[0].imshow(original_crop)
    axes[0].set_title(f"Original Color (Zoom)", fontsize=10)
    axes[0].axis('off')

    axes[1].imshow(reconstructed_crop)
    axes[1].set_title(f"Reconstructed Color (Zoom)", fontsize=10)
    axes[1].axis('off')

    plt.suptitle(
        f"Qualitative Comparison (Peppers - SSIM: {ss_metric:.4f}): Full Color Preservation",
        fontsize=12
    )
    plt.tight_layout()
    plt.show()

# --- 4. Main Execution for Peppers Analysis ---

image_path = "/content/peppers.jpg"
PEPPERS_SSIM = 0.9385 # Value from your Table II

L_orig, A_orig, B_orig = convert_to_LAB(image_path)

L_key, A_key, B_key = generate_aes_key(), generate_aes_key(), generate_aes_key()

L_encrypted, L_iv, L_padding = encrypt_channel(L_orig, L_key)
A_encrypted, A_iv, A_padding = encrypt_channel(A_orig, A_key)
B_encrypted, B_iv, B_padding = encrypt_channel(B_orig, B_key)

L_shares = generate_dynamic_shares(L_encrypted, L_orig.shape)
A_shares = generate_dynamic_shares(A_encrypted, A_orig.shape)
B_shares = generate_dynamic_shares(B_encrypted, B_orig.shape)

L_decrypted = decrypt_channel(L_encrypted, L_key, L_iv, L_orig.shape)
A_decrypted = decrypt_channel(A_encrypted, A_key, A_iv, A_orig.shape)
B_decrypted = decrypt_channel(B_encrypted, B_key, B_iv, B_orig.shape)


perform_qualitative_comparison_color(L_orig, A_orig, B_orig, L_decrypted, A_decrypted, B_decrypted, PEPPERS_SSIM)

"""# CODE FOR ASSESSING SD AND VARIANCE TO PROVE STATISTICAL SIGNFICANCE OF DATA"""

import numpy as np
import pandas as pd
import math

# --- Data from your Table II ---
data = {
    'Image': ['Peppers', 'Baboon', 'Airplane (F-16)', 'Sailboat on Lake'],
    'PSNR_dB': [23.18, 24.73, 33.84, 28.86],
    'SSIM': [0.9385, 0.9565, 0.9862, 0.9743],
    'MSE': [312.99, 219.04, 26.89, 84.62]
}

df = pd.DataFrame(data)

psnr_mean = df['PSNR_dB'].mean()
psnr_sd = df['PSNR_dB'].std()
psnr_variance = df['PSNR_dB'].var()

ssim_mean = df['SSIM'].mean()
ssim_sd = df['SSIM'].std()
ssim_variance = df['SSIM'].var()

mse_mean = df['MSE'].mean()
mse_sd = df['MSE'].std()
mse_variance = df['MSE'].var()


print("\n--- Statistical Analysis Results (PSNR) ---")
print(f"PSNR Mean (as reported): {psnr_mean:.2f} dB")
print(f"PSNR Standard Deviation (SD): {psnr_sd:.4f}")
print(f"PSNR Variance: {psnr_variance:.4f}")

print("\n--- Statistical Analysis Results (SSIM) ---")
print(f"SSIM Mean (as reported): {ssim_mean:.4f}")
print(f"SSIM Standard Deviation (SD): {ssim_sd:.4f}")
print(f"SSIM Variance: {ssim_variance:.4f}")

print("\n--- Statistical Analysis Results (MSE) ---")
print(f"MSE Mean (as reported): {mse_mean:.2f}")
print(f"MSE Standard Deviation (SD): {mse_sd:.4f}")
print(f"MSE Variance: {mse_variance:.4f}")

print("\n--- Content to Insert in Table II (New Row: Standard Deviation) ---")
print(f"Standard Deviation: PSNR={psnr_sd:.4f}, SSIM={ssim_sd:.4f}, MSE={mse_sd:.4f}")